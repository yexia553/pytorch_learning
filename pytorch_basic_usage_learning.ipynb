{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Tensor的创建"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import torch\r\n",
                "\r\n",
                "a = torch.Tensor([[1, 2], [3, 4]])\r\n",
                "print(a)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[1., 2.],\n",
                        "        [3., 4.]])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "a = torch.Tensor(2, 2)\r\n",
                "# 只指定size不指定值，每次的值都不一样，是随机的，或者说就是相应内存地址中原本的值\r\n",
                "print(a)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[4.0000e+00, 4.5914e-41],\n",
                        "        [0.0000e+00, 0.0000e+00]])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "a = torch.Tensor(((2, 2), (2, 2)))\r\n",
                "print(a)\r\n",
                "print(a.dtype)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[2., 2.],\n",
                        "        [2., 2.]])\n",
                        "torch.float32\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Tensor 的属性"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# 用GPU进行处理\r\n",
                "dev = torch.device('cuda:0')\r\n",
                "a = torch.tensor([2, 2], dtype=torch.float32, device=dev)\r\n",
                "print(a)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([2., 2.], device='cuda:0')\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "i = torch.Tensor([[0, 1, 2], [0, 1, 2]])\r\n",
                "v = torch.Tensor([1, 2, 3])\r\n",
                "a = torch.sparse_coo_tensor(i, v, [4, 4], dtype=torch.float32, device=dev)\r\n",
                "b= a.to_dense()\r\n",
                "print(a)\r\n",
                "print(b)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor(indices=tensor([[0, 1, 2],\n",
                        "                       [0, 1, 2]]),\n",
                        "       values=tensor([1., 2., 3.]),\n",
                        "       device='cuda:0', size=(4, 4), nnz=3, layout=torch.sparse_coo)\n",
                        "tensor([[1., 0., 0., 0.],\n",
                        "        [0., 2., 0., 0.],\n",
                        "        [0., 0., 3., 0.],\n",
                        "        [0., 0., 0., 0.]], device='cuda:0')\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Tensor 中的原位操作（in-place）\r\n",
                "例如：\r\n",
                "torch.sum_()\r\n",
                "\r\n",
                "其实就是不占用的新的内存，在原来的内存地址上进行操作"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Tensor的广播机制\r\n",
                "就是当tenser的shape不一样的时候，如果相加，会自动进行自动补齐，但是要满足“右对齐”：从右往左看，每一位上的值要么有1要么相等，如果维度不够的，用1补齐"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "\r\n",
                "a = torch.rand(2, 2)\r\n",
                "b = torch.rand(1, 2)\r\n",
                "c = a + b\r\n",
                "print(a)\r\n",
                "print(b)\r\n",
                "print(c)\r\n",
                "print(c.shape)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[0.2373, 0.9350],\n",
                        "        [0.8477, 0.4104]])\n",
                        "tensor([[0.4785, 0.9962]])\n",
                        "tensor([[0.7158, 1.9312],\n",
                        "        [1.3262, 1.4066]])\n",
                        "torch.Size([2, 2])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "a = torch.rand(1, 2, 4, 3)\r\n",
                "b = torch.rand(1, 3)\r\n",
                "c = a + b\r\n",
                "print(a)\r\n",
                "print(b)\r\n",
                "print(c)\r\n",
                "print(c.shape)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[[[0.1068, 0.6422, 0.9731],\n",
                        "          [0.1456, 0.7996, 0.7660],\n",
                        "          [0.1113, 0.3376, 0.6956],\n",
                        "          [0.7478, 0.6095, 0.6693]],\n",
                        "\n",
                        "         [[0.9000, 0.1734, 0.5806],\n",
                        "          [0.5083, 0.7554, 0.7050],\n",
                        "          [0.2962, 0.0287, 0.4188],\n",
                        "          [0.2682, 0.3925, 0.1323]]]])\n",
                        "tensor([[0.5158, 0.4086, 0.6542]])\n",
                        "tensor([[[[0.6226, 1.0508, 1.6272],\n",
                        "          [0.6614, 1.2082, 1.4202],\n",
                        "          [0.6271, 0.7462, 1.3498],\n",
                        "          [1.2636, 1.0181, 1.3235]],\n",
                        "\n",
                        "         [[1.4158, 0.5820, 1.2347],\n",
                        "          [1.0241, 1.1640, 1.3592],\n",
                        "          [0.8120, 0.4373, 1.0729],\n",
                        "          [0.7840, 0.8011, 0.7864]]]])\n",
                        "torch.Size([1, 2, 4, 3])\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# tensor 中取整，取余"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "a = torch.rand(2, 2) * 10\r\n",
                "print(a)\r\n",
                "print(a.floor())  # 向下取整\r\n",
                "print(a.ceil())  # 向上取整\r\n",
                "print(a.round())  # 四舍五入\r\n",
                "print(a.trunc())  # 取整数部分\r\n",
                "print(a.frac())  # 取小数部分\r\n",
                "print(a%2)  # 取余数\r\n",
                "b = torch.tensor([[2, 3], [4, 5]], dtype=torch.float32)\r\n",
                "## 以下两个用法可以参考文档：\r\n",
                "## https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch/\r\n",
                "print(torch.fmod(a, b))  # 取余数，a是被取余数， 结果的正负号与a里面的值相同\r\n",
                "print(torch.remainder(a, b))  # 取余数，a是被取余数， 结果的正负号与b里面的值相同"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[5.9712, 5.8541],\n",
                        "        [2.6980, 3.2548]])\n",
                        "tensor([[5., 5.],\n",
                        "        [2., 3.]])\n",
                        "tensor([[6., 6.],\n",
                        "        [3., 4.]])\n",
                        "tensor([[6., 6.],\n",
                        "        [3., 3.]])\n",
                        "tensor([[5., 5.],\n",
                        "        [2., 3.]])\n",
                        "tensor([[0.9712, 0.8541],\n",
                        "        [0.6980, 0.2548]])\n",
                        "tensor([[1.9712, 1.8541],\n",
                        "        [0.6980, 1.2548]])\n",
                        "tensor([[1.9712, 2.8541],\n",
                        "        [2.6980, 3.2548]])\n",
                        "tensor([[1.9712, 2.8541],\n",
                        "        [2.6980, 3.2548]])\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.6 64-bit ('venv': venv)"
        },
        "interpreter": {
            "hash": "0229fb1c092e92b2d6a4aa39c5427cae1e13738bd1c22b3a2c141f6975cbc0e7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}